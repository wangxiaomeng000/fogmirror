# 认知考古图片识别功能测试指南

## 测试准备
1. 确保前端运行在 http://localhost:3000
2. 确保后端运行在 http://localhost:3001
3. 访问 http://localhost:3000/cognitive-archaeology

## 测试步骤

### 测试1: 基本图片上传功能
1. 点击"添加图片"按钮
2. 选择任意图片文件
3. 在输入框输入描述文字，例如："刚刚看完展会"
4. 点击发送按钮

**预期结果**：
- ✅ 图片应该显示在对话中
- ✅ AI应该回复与图片相关的问题，例如：
  - "这张图片是在什么场景下拍摄的？"
  - "拍这张照片时，你的心情是怎样的？"
  - "图片中哪个细节最触动你？"
- ✅ 左侧认知地图应该生成节点

### 测试2: 验证图片理解
1. 继续上面的对话
2. 回复AI的问题，例如："是的，这是今天在展会上拍的"

**预期结果**：
- ✅ AI应该基于之前的图片继续深入提问
- ✅ 认知地图应该增加新的节点和连接

### 测试3: 纯文字对话（对比测试）
1. 刷新页面
2. 不上传图片，只输入文字："刚刚看完展会"
3. 点击发送

**预期结果**：
- AI的回复应该与有图片时不同
- 可能会问更多关于展会细节的问题

## 成功标准
- ✅ 图片能正确上传和显示
- ✅ AI能识别图片并生成相关问题
- ✅ 认知节点能正确创建和显示
- ✅ 对话能保持上下文连贯性

## 常见问题
1. 如果点击发送没反应：检查控制台是否有错误
2. 如果AI回复通用问题：可能是图片识别失败，检查后端日志
3. 如果认知地图不更新：检查Socket连接是否正常
EOF < /dev/null